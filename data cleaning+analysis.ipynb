{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据清洗\n",
        "import pandas as pd\n",
        "\n",
        "df_comment = pd.read_csv(r'D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-free loop\\bili_covers_comments_free_loop_ai翻唱_20251107_010951.csv')\n",
        "df_danmu = pd.read_csv(r'\"D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-free loop\\bili_covers_danmu_free_loop_ai翻唱_20251107_010951.csv\"')\n",
        "df_summary = pd.read_csv(r'\"D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-free loop\\bili_covers_summary_free_loop_ai翻唱_20251107_010951.csv\"')\n",
        "\n",
        "\n",
        "# 去除重复值\n",
        "df_comment = df_comment.drop_duplicates()\n",
        "df_danmu = df_danmu.drop_duplicates()\n",
        "df_summary = df_summary.drop_duplicates()\n",
        "\n",
        "# 处理缺失值（此处采用删除缺失值的方式）\n",
        "df_comment = df_comment.dropna()\n",
        "df_danmu = df_danmu.dropna()\n",
        "df_summary = df_summary.dropna()\n",
        "\n",
        "# 转换时间类型（将字符串格式的时间转换为datetime类型）\n",
        "df_comment['ctime'] = pd.to_datetime(df_comment['ctime'])  #评论时间\n",
        "df_summary['pubdate'] = pd.to_datetime(df_summary['pubdate'])  #视频发布时间\n",
        "\n",
        "# 保存清洗后的数据为Excel文件\n",
        "with pd.ExcelWriter('D:/A CITYUSAMA/5507final/cleaned_data.xlsx') as writer:\n",
        "    df_comment.to_excel(writer, sheet_name='comment', index=False)  #不保留索引列\n",
        "    df_danmu.to_excel(writer, sheet_name='danmu', index=False)\n",
        "    df_summary.to_excel(writer, sheet_name='summary', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "!pip install jieba\n",
        "!pip install snownlp\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import jieba\n",
        "from snownlp import SnowNLP\n",
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "class MultiDatasetSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.comment_datasets = []\n",
        "        self.danmu_datasets = []\n",
        "        self.all_comments = pd.DataFrame()\n",
        "        self.all_danmu = pd.DataFrame()\n",
        "        \n",
        "    def load_datasets(self, file_patterns):\n",
        "     \n",
        "        file_patterns: [r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\freeloop\\cleaned_data.xlsx', r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\onelastkiss\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\红莲华\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\红色高跟鞋\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\极乐净土\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\开心往前飞\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\牵丝戏\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\晴天\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\我用什么把你留住\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺'\n",
        "                        ]\n",
        "         \n",
        "        all_files = [r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\freeloop\\cleaned_data.xlsx', r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\onelastkiss\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\红莲华\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\红色高跟鞋\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\极乐净土\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\开心往前飞\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\牵丝戏\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\晴天\\cleaned_data.xlsx',\n",
        "                        r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\我用什么把你留住\\cleaned_data.xlsx',r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺']\n",
        "        for pattern in file_patterns:\n",
        "            if '*' in pattern:\n",
        "                matched_files = glob.glob(pattern)\n",
        "                all_files.extend(matched_files)  # 直接扩展列表，不检查存在性\n",
        "            else:\n",
        "                all_files.append(pattern)\n",
        "        if not all_files:\n",
        "            print(\"尝试其他扩展名...\")\n",
        "            for ext in ['*.xls', '*.xlsx', '*.xlsm']:\n",
        "                matched_files = glob.glob(ext)\n",
        "                print(f\"扩展名 '{ext}' 匹配到的文件: {matched_files}\")\n",
        "                all_files.extend(matched_files)\n",
        "        \n",
        "        all_files = [f for f in all_files if os.path.exists(f)]\n",
        "        print(f\"最终找到的文件: {all_files}\")\n",
        "# 然后过滤掉不存在的文件\n",
        "        all_files = [f for f in all_files if os.path.exists(f)]\n",
        "        \n",
        "        print(f\"找到文件: {all_files}\")\n",
        "        \n",
        "        for file_path in all_files:\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"文件不存在: {file_path}\")\n",
        "                continue\n",
        "                \n",
        "            try:\n",
        "                # 读取Excel文件的不同sheet\n",
        "                excel_file = pd.ExcelFile(file_path)\n",
        "                sheet_names = excel_file.sheet_names\n",
        "                \n",
        "                # 识别评论和弹幕sheet\n",
        "                comment_sheets = [s for s in sheet_names if 'comment' in s.lower()]\n",
        "                danmu_sheets = [s for s in sheet_names if 'danmu' in s.lower() or 'dannu' in s.lower()]\n",
        "                \n",
        "                # 读取评论数据\n",
        "                for sheet in comment_sheets:\n",
        "                    df = pd.read_excel(file_path, sheet_name=sheet)\n",
        "                    df['source_file'] = file_path\n",
        "                    df['source_sheet'] = sheet\n",
        "                    self.comment_datasets.append(df)\n",
        "                    print(f\"从 {file_path} 加载评论数据: {sheet} - {len(df)} 行\")\n",
        "                \n",
        "                # 读取弹幕数据\n",
        "                for sheet in danmu_sheets:\n",
        "                    df = pd.read_excel(file_path, sheet_name=sheet)\n",
        "                    df['source_file'] = file_path\n",
        "                    df['source_sheet'] = sheet\n",
        "                    self.danmu_datasets.append(df)\n",
        "                    print(f\"从 {file_path} 加载弹幕数据: {sheet} - {len(df)} 行\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"读取文件 {file_path} 时出错: {str(e)}\")\n",
        "        \n",
        "        # 合并所有数据集\n",
        "        if self.comment_datasets:\n",
        "            self.all_comments = pd.concat(self.comment_datasets, ignore_index=True)\n",
        "        if self.danmu_datasets:\n",
        "            self.all_danmu = pd.concat(self.danmu_datasets, ignore_index=True)\n",
        "            \n",
        "        print(f\"总共加载: {len(self.all_comments)} 条评论, {len(self.all_danmu)} 条弹幕\")\n",
        "    \n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"文本预处理\"\"\"\n",
        "        if pd.isna(text):\n",
        "            return \"\"\n",
        "        text = str(text)\n",
        "        # 去除特殊字符但保留中文标点用于情感分析\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub(r'[@#]\\w+', '', text)\n",
        "        text = re.sub(r'\\[.*?\\]', '', text) \n",
        "        text = re.sub(r'卧槽+', '', text)\n",
        "        text = re.sub(r'展麟+', '', text)\n",
        "        text = re.sub(r'回复+', '', text) \n",
        "        text = re.sub(r'不是+', '', text)\n",
        "        text = re.sub(r'就是+', '', text)\n",
        "        text = re.sub(r'这个+', '', text)\n",
        "        text = re.sub(r'啊啊啊+', '', text)\n",
        "        text = re.sub(r'一个+', '', text)\n",
        "        text = re.sub(r'大哥+', '', text)\n",
        "        text = re.sub(r'什么+', '', text)# 去除表情标签\n",
        "        return text.strip()\n",
        "    \n",
        "    def analyze_sentiment(self, text):\n",
        "        \"\"\"情感分析\"\"\"\n",
        "        if not text or len(text.strip()) < 2:\n",
        "            return 0.5  # 中性\n",
        "        try:\n",
        "            s = SnowNLP(text)\n",
        "            return s.sentiments\n",
        "        except:\n",
        "            return 0.5\n",
        "    \n",
        "    def sentiment_category(self, score):\n",
        "        \"\"\"情感分类\"\"\"\n",
        "        if score >= 0.7:\n",
        "            return '积极'\n",
        "        elif score <= 0.3:\n",
        "            return '消极'\n",
        "        else:\n",
        "            return '中性'\n",
        "    \n",
        "    def generate_wordclouds(self):\n",
        "        \"\"\"生成词云图\"\"\"\n",
        "        # 预处理文本\n",
        "        if not self.all_comments.empty:\n",
        "            self.all_comments['clean_text'] = self.all_comments.iloc[:, 1].apply(self.preprocess_text)  # 第二列通常是文本\n",
        "        if not self.all_danmu.empty:\n",
        "            self.all_danmu['clean_text'] = self.all_danmu.iloc[:, 2].apply(self.preprocess_text)  # 第三列通常是弹幕文本\n",
        "        \n",
        "        # 生成评论词云\n",
        "        if not self.all_comments.empty:\n",
        "            comment_text = ' '.join(self.all_comments['clean_text'].dropna().tolist())\n",
        "            self._generate_single_wordcloud(comment_text, \"多数据集评论词云图\", 'viridis')\n",
        "        \n",
        "        # 生成弹幕词云\n",
        "        if not self.all_danmu.empty:\n",
        "            danmu_text = ' '.join(self.all_danmu['clean_text'].dropna().tolist())\n",
        "            self._generate_single_wordcloud(danmu_text, \"多数据集弹幕词云图\", 'plasma')\n",
        "    \n",
        "    def _generate_single_wordcloud(self, text, title, colormap):\n",
        "        \"\"\"生成单个词云图\"\"\"\n",
        "        if not text:\n",
        "            print(f\"没有文本数据生成 {title}\")\n",
        "            return\n",
        "        \n",
        "        # 使用jieba分词\n",
        "        words = jieba.lcut(text)\n",
        "        # 过滤停用词\n",
        "        stop_words = {'的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这'}\n",
        "        filtered_words = [word for word in words if len(word) > 1 and word not in stop_words and not word.isdigit()]\n",
        "        word_freq = Counter(filtered_words)\n",
        "        \n",
        "        # 创建词云\n",
        "        wordcloud = WordCloud(\n",
        "            font_path='simhei.ttf',\n",
        "            width=1000,\n",
        "            height=700,\n",
        "            background_color='white',\n",
        "            colormap=colormap,\n",
        "            max_words=150,\n",
        "            relative_scaling=0.5\n",
        "        ).generate_from_frequencies(word_freq)\n",
        "        \n",
        "        # 显示词云\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.title(title, fontsize=20, fontweight='bold', pad=20)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # 显示高频词\n",
        "        top_words = word_freq.most_common(15)\n",
        "        print(f\"\\n{title} - 前15个高频词:\")\n",
        "        for word, count in top_words:\n",
        "            print(f\"  {word}: {count}\")\n",
        "    \n",
        "    def perform_sentiment_analysis(self, sample_size=2000):\n",
        "        \"\"\"执行情感分析\"\"\"\n",
        "        print(\"开始情感分析...\")\n",
        "        \n",
        "        # 评论情感分析\n",
        "        if not self.all_comments.empty:\n",
        "            comments_clean = self.all_comments.copy()\n",
        "            if 'clean_text' not in comments_clean.columns:\n",
        "                comments_clean['clean_text'] = comments_clean.iloc[:, 1].apply(self.preprocess_text)\n",
        "            \n",
        "            comments_clean = comments_clean[comments_clean['clean_text'].str.len() > 1]\n",
        "            \n",
        "            # 抽样\n",
        "            sample_comments = comments_clean.sample(\n",
        "                n=min(sample_size, len(comments_clean)), \n",
        "                random_state=42\n",
        "            ) if len(comments_clean) > sample_size else comments_clean\n",
        "            \n",
        "            sample_comments['sentiment_score'] = sample_comments['clean_text'].apply(self.analyze_sentiment)\n",
        "            sample_comments['sentiment'] = sample_comments['sentiment_score'].apply(self.sentiment_category)\n",
        "            sample_comments['type'] = '评论'\n",
        "            self.comment_sentiment = sample_comments\n",
        "            print(f\"评论情感分析完成: {len(sample_comments)} 条样本\")\n",
        "        \n",
        "        # 弹幕情感分析\n",
        "        if not self.all_danmu.empty:\n",
        "            danmu_clean = self.all_danmu.copy()\n",
        "            if 'clean_text' not in danmu_clean.columns:\n",
        "                danmu_clean['clean_text'] = danmu_clean.iloc[:, 2].apply(self.preprocess_text)\n",
        "            \n",
        "            danmu_clean = danmu_clean[danmu_clean['clean_text'].str.len() > 1]\n",
        "            \n",
        "            # 抽样\n",
        "            sample_danmu = danmu_clean.sample(\n",
        "                n=min(sample_size, len(danmu_clean)), \n",
        "                random_state=42\n",
        "            ) if len(danmu_clean) > sample_size else danmu_clean\n",
        "            \n",
        "            sample_danmu['sentiment_score'] = sample_danmu['clean_text'].apply(self.analyze_sentiment)\n",
        "            sample_danmu['sentiment'] = sample_danmu['sentiment_score'].apply(self.sentiment_category)\n",
        "            sample_danmu['type'] = '弹幕'\n",
        "            self.danmu_sentiment = sample_danmu\n",
        "            print(f\"弹幕情感分析完成: {len(sample_danmu)} 条样本\")\n",
        "        \n",
        "        # 合并所有情感分析结果\n",
        "        all_sentiment = pd.DataFrame()\n",
        "        if hasattr(self, 'comment_sentiment'):\n",
        "            all_sentiment = pd.concat([all_sentiment, self.comment_sentiment], ignore_index=True)\n",
        "        if hasattr(self, 'danmu_sentiment'):\n",
        "            all_sentiment = pd.concat([all_sentiment, self.danmu_sentiment], ignore_index=True)\n",
        "            \n",
        "        self.all_sentiment = all_sentiment\n",
        "        print(f\"情感分析完成，总共 {len(all_sentiment)} 条样本\")\n",
        "    \n",
        "    def create_interactive_sentiment_charts(self):\n",
        "        \"\"\"创建交互式情感分析图表\"\"\"\n",
        "        if not hasattr(self, 'all_sentiment') or self.all_sentiment.empty:\n",
        "            print(\"没有情感分析数据可用\")\n",
        "            return\n",
        "        \n",
        "        # 1. 情感分布对比图\n",
        "        sentiment_counts = self.all_sentiment.groupby(['type', 'sentiment']).size().reset_index(name='count')\n",
        "        \n",
        "        fig_dist = px.sunburst(\n",
        "            sentiment_counts, \n",
        "            path=['type', 'sentiment'], \n",
        "            values='count',\n",
        "            title='评论与弹幕情感分布对比',\n",
        "            color='sentiment',\n",
        "            color_discrete_map={'积极': '#2E8B57', '消极': '#FF6B6B', '中性': '#4ECDC4'}\n",
        "        )\n",
        "        fig_dist.update_layout(height=600)\n",
        "        \n",
        "        # 2. 情感分数分布小提琴图\n",
        "        fig_violin = px.violin(\n",
        "            self.all_sentiment, \n",
        "            x='type', \n",
        "            y='sentiment_score',\n",
        "            color='type',\n",
        "            box=True,\n",
        "            points=\"all\",\n",
        "            title='情感分数分布对比',\n",
        "            labels={'sentiment_score': '情感分数', 'type': '类型'}\n",
        "        )\n",
        "        fig_violin.update_layout(height=500)\n",
        "        \n",
        "        # 3. 情感比例堆叠条形图\n",
        "        sentiment_pivot = self.all_sentiment.groupby(['type', 'sentiment']).size().unstack(fill_value=0)\n",
        "        sentiment_percent = sentiment_pivot.div(sentiment_pivot.sum(axis=1), axis=0) * 100\n",
        "        \n",
        "        fig_stacked = go.Figure()\n",
        "        for sentiment in ['积极', '中性', '消极']:\n",
        "            if sentiment in sentiment_percent.columns:\n",
        "                fig_stacked.add_trace(go.Bar(\n",
        "                    name=sentiment,\n",
        "                    x=sentiment_percent.index,\n",
        "                    y=sentiment_percent[sentiment],\n",
        "                    marker_color={'积极': '#2E8B57', '中性': '#4ECDC4', '消极': '#FF6B6B'}[sentiment]\n",
        "                ))\n",
        "        \n",
        "        fig_stacked.update_layout(\n",
        "            title='情感比例分布 (%)',\n",
        "            barmode='stack',\n",
        "            yaxis_title='百分比 (%)',\n",
        "            height=500\n",
        "        )\n",
        "        \n",
        "        # 4. 数据集来源分析\n",
        "        if 'source_file' in self.all_sentiment.columns:\n",
        "            source_sentiment = self.all_sentiment.groupby(['source_file', 'type', 'sentiment']).size().reset_index(name='count')\n",
        "            \n",
        "            fig_source = px.treemap(\n",
        "                source_sentiment,\n",
        "                path=['source_file', 'type', 'sentiment'],\n",
        "                values='count',\n",
        "                title='各数据集情感分布',\n",
        "                color='sentiment',\n",
        "                color_discrete_map={'积极': '#2E8B57', '消极': '#FF6B6B', '中性': '#4ECDC4'}\n",
        "            )\n",
        "            fig_source.update_layout(height=600)\n",
        "        else:\n",
        "            fig_source = go.Figure()\n",
        "            fig_source.add_annotation(text=\"无来源数据\", x=0.5, y=0.5, showarrow=False)\n",
        "            fig_source.update_layout(title=\"各数据集情感分布\", height=400)\n",
        "        \n",
        "        # 5. 情感统计摘要\n",
        "        sentiment_stats = self.all_sentiment.groupby('type').agg({\n",
        "            'sentiment_score': ['count', 'mean', 'std'],\n",
        "        }).round(3)\n",
        "        \n",
        "        sentiment_stats.columns = ['样本数', '平均情感分数', '标准差']\n",
        "        sentiment_stats = sentiment_stats.reset_index()\n",
        "        \n",
        "        # 情感比例统计\n",
        "        sentiment_ratio = self.all_sentiment.groupby(['type', 'sentiment']).size().unstack(fill_value=0)\n",
        "        sentiment_ratio_pct = (sentiment_ratio.div(sentiment_ratio.sum(axis=1), axis=0) * 100).round(1)\n",
        "        \n",
        "        for sentiment in ['积极', '中性', '消极']:\n",
        "            if sentiment in sentiment_ratio_pct.columns:\n",
        "                sentiment_stats[f'{sentiment}比例(%)'] = sentiment_ratio_pct[sentiment].values\n",
        "        \n",
        "        # 创建统计表格\n",
        "        fig_table = go.Figure(data=[go.Table(\n",
        "            header=dict(\n",
        "                values=list(sentiment_stats.columns),\n",
        "                fill_color='lightblue',\n",
        "                align='center',\n",
        "                font=dict(size=12, color='black')\n",
        "            ),\n",
        "            cells=dict(\n",
        "                values=[sentiment_stats[col] for col in sentiment_stats.columns],\n",
        "                fill_color='lavender',\n",
        "                align='center'\n",
        "            )\n",
        "        )])\n",
        "        \n",
        "        fig_table.update_layout(\n",
        "            title='情感分析统计摘要',\n",
        "            height=300\n",
        "        )\n",
        "        \n",
        "        # 显示所有图表\n",
        "        print(\"生成交互式情感分析图表...\")\n",
        "        fig_dist.show()\n",
        "        fig_violin.show()\n",
        "        fig_stacked.show()\n",
        "        fig_source.show()\n",
        "        fig_table.show()\n",
        "        \n",
        "        # 打印统计摘要\n",
        "        print(\"\\n=== 情感分析统计摘要 ===\")\n",
        "        print(sentiment_stats.to_string(index=False))\n",
        "        \n",
        "        # 情感强度分析\n",
        "        def sentiment_intensity(df, name):\n",
        "            scores = df['sentiment_score']\n",
        "            intensity = np.abs(scores - 0.5).mean()\n",
        "            positivity = len(df[df['sentiment'] == '积极']) / len(df)\n",
        "            return intensity, positivity\n",
        "        \n",
        "        if hasattr(self, 'comment_sentiment'):\n",
        "            intensity, positivity = sentiment_intensity(self.comment_sentiment, \"评论\")\n",
        "            print(f\"\\n评论情感分析:\")\n",
        "            print(f\"  情感强度: {intensity:.3f} (0=中性, 0.5=极端)\")\n",
        "            print(f\"  积极比例: {positivity:.1%}\")\n",
        "        \n",
        "        if hasattr(self, 'danmu_sentiment'):\n",
        "            intensity, positivity = sentiment_intensity(self.danmu_sentiment, \"弹幕\")\n",
        "            print(f\"\\n弹幕情感分析:\")\n",
        "            print(f\"  情感强度: {intensity:.3f} (0=中性, 0.5=极端)\")\n",
        "            print(f\"  积极比例: {positivity:.1%}\")\n",
        "\n",
        "# 使用示例\n",
        "def main():\n",
        "    # 创建分析器实例\n",
        "    analyzer = MultiDatasetSentimentAnalyzer()\n",
        "    \n",
        "    # 加载多个数据集\n",
        "    # 方法1: 指定具体文件\n",
        "    # file_patterns = ['cleaned_data(fl).xlsx', 'another_data.xlsx']\n",
        "    \n",
        "    # 方法2: 使用通配符加载所有匹配文件\n",
        "    file_patterns = ['*.xlsx']  # 加载当前目录所有Excel文件\n",
        "    \n",
        "    analyzer.load_datasets(file_patterns)\n",
        "    \n",
        "    # 生成词云图\n",
        "    print(\"\\n生成词云图...\")\n",
        "    analyzer.generate_wordclouds()\n",
        "    \n",
        "    # 执行情感分析\n",
        "    print(\"\\n执行情感分析...\")\n",
        "    analyzer.perform_sentiment_analysis(sample_size=2000)\n",
        "    \n",
        "    # 创建交互式情感分析图表\n",
        "    print(\"\\n创建交互式情感分析图表...\")\n",
        "    analyzer.create_interactive_sentiment_charts()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7XvjYwKQMGU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import pi\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# -------------------------- 1. 基础设置（中文字体、样式、颜色）--------------------------\n",
        "plt.rcParams[\"font.family\"] = [\"WenQuanYi Zen Hei\", \"SimHei\"]\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示\n",
        "plt.rcParams['figure.dpi'] = 300  # 高清分辨率\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['grid.color'] = '#e0e0e0'\n",
        "\n",
        "# 定义两类视频的颜色（AI：科技蓝，人类：温暖橙）\n",
        "colors = {'AI': '#2c7fb8', '人类': '#ff7f00'}\n",
        "labels = {'AI': 'AI生成视频', '人类': '人类创作视频'}\n",
        "\n",
        "# -------------------------- 2. 加载数据并预处理 --------------------------\n",
        "def load_and_preprocess(file_path, video_type):\n",
        "    \"\"\"加载Excel数据，添加视频类型标签，计算衍生指标\"\"\"\n",
        "    # 读取summary工作表（视频核心数据）\n",
        "    df = pd.read_excel(file_path, sheet_name='summary')\n",
        "\n",
        "    # 添加视频类型标签\n",
        "    df['video_type'] = video_type\n",
        "\n",
        "    # 计算关键衍生指标（转化率）\n",
        "    df['like_rate'] = (df['like'] / df['view'] * 100).round(3)  # 点赞率（%）\n",
        "    df['favorite_rate'] = (df['favorite'] / df['view'] * 100).round(3)  # 收藏率（%）\n",
        "    df['coin_rate'] = (df['coin'] / df['view'] * 100).round(3)  # 投币率（%）\n",
        "\n",
        "    # 转换发布时间为datetime类型\n",
        "    df['pubdate'] = pd.to_datetime(df['pubdate'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# 请替换为你的实际文件路径\n",
        "# 加载AI视频和人类视频数据（注意：这里使用你提供的文件名格式）\n",
        "df_ai = load_and_preprocess(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\freeloop\\cleaned_data.xlsx', 'AI')\n",
        "df_human = load_and_preprocess(r'D:\\A CITYUSAMA\\5507final\\cleaned_data(fl).xlsx', '人类')\n",
        "\n",
        "\n",
        "# 合并数据（用于统一分析）\n",
        "df_combined = pd.concat([df_ai, df_human], ignore_index=True)\n",
        "\n",
        "# 定义需要对比的核心指标\n",
        "core_metrics = ['view', 'like', 'coin', 'favorite', 'share', 'danmaku', 'reply_count']\n",
        "rate_metrics = ['like_rate', 'favorite_rate', 'coin_rate']  # 转化率指标\n",
        "\n",
        "\n",
        "# -------------------------- 3. 图表1：整体互动水平对比（箱线图）--------------------------\n",
        "plt.figure(figsize=(15, 8))\n",
        "# 选择4个核心指标对比（修复此处的KeyError问题）\n",
        "metrics_to_plot = ['view', 'like', 'favorite', 'danmaku']\n",
        "# 对播放量取对数（因数值范围可能极大，避免掩盖其他指标差异）\n",
        "df_combined['view_log'] = np.log10(df_combined['view'] + 1)  # +1避免log(0)\n",
        "\n",
        "# 修正：完善指标名称映射（添加'view'的对应关系）\n",
        "metric_names = {\n",
        "    'view': '播放量',  # 新增这一行，解决KeyError\n",
        "    'view_log': '播放量（log10）',\n",
        "    'like': '点赞数',\n",
        "    'favorite': '收藏数',\n",
        "    'danmaku': '弹幕数'\n",
        "}\n",
        "\n",
        "# 绘制箱线图\n",
        "positions = []\n",
        "box_data = []\n",
        "tick_labels = []\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    # 计算每个指标的位置（AI在左，人类在右，间隔0.8）\n",
        "    pos_ai = i * 2\n",
        "    pos_human = i * 2 + 0.8\n",
        "\n",
        "    # 添加AI和人类的数据（播放量使用原始值，图表中会显示log转换后的标签）\n",
        "    box_data.append(df_ai[metric])\n",
        "    box_data.append(df_human[metric])\n",
        "\n",
        "    # 记录位置和标签（播放量显示log10标签，其他用原始名称）\n",
        "    if metric == 'view':\n",
        "        tick_labels.append(metric_names['view_log'])  # 显示log转换后的名称\n",
        "    else:\n",
        "        tick_labels.append(metric_names[metric])\n",
        "    positions.extend([pos_ai, pos_human])\n",
        "\n",
        "# 绘制箱线图\n",
        "boxes = plt.boxplot(box_data, positions=positions, widths=0.6, patch_artist=True)\n",
        "\n",
        "# 给箱线图上色（AI蓝、人类橙）\n",
        "for i, box in enumerate(boxes['boxes']):\n",
        "    if i % 2 == 0:  # 偶数索引为AI视频\n",
        "        box.set_facecolor(colors['AI'])\n",
        "        box.set_alpha(0.7)\n",
        "    else:  # 奇数索引为人类视频\n",
        "        box.set_facecolor(colors['人类'])\n",
        "        box.set_alpha(0.7)\n",
        "\n",
        "# 添加图例\n",
        "legend_elements = [\n",
        "    Patch(facecolor=colors['AI'], alpha=0.7, label=labels['AI']),\n",
        "    Patch(facecolor=colors['人类'], alpha=0.7, label=labels['人类'])\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
        "\n",
        "# 设置标签和标题\n",
        "plt.xticks([i*2 + 0.4 for i in range(len(metrics_to_plot))], tick_labels, fontsize=11)\n",
        "plt.ylabel('数值（播放量已做log10转换）', fontsize=12)\n",
        "plt.title('AI vs 人类视频：整体互动水平对比（箱线图）', fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -------------------------- 4. 图表2：关键指标均值对比（分组柱状图）--------------------------\n",
        "plt.figure(figsize=(14, 8))\n",
        "# 选择5个关键指标（含转化率）\n",
        "mean_metrics = ['view', 'like', 'favorite', 'like_rate', 'favorite_rate']\n",
        "mean_metric_names = {\n",
        "    'view': '平均播放量（log10）',  # 明确标注log转换\n",
        "    'like': '平均点赞数',\n",
        "    'favorite': '平均收藏数',\n",
        "    'like_rate': '平均点赞率（%）',\n",
        "    'favorite_rate': '平均收藏率（%）'\n",
        "}\n",
        "\n",
        "# 计算两类视频的均值（播放量取对数，避免数值过大）\n",
        "ai_means = []\n",
        "human_means = []\n",
        "for metric in mean_metrics:\n",
        "    if metric == 'view':\n",
        "        # 播放量取对数后计算均值\n",
        "        ai_mean = np.log10(df_ai[metric] + 1).mean()\n",
        "        human_mean = np.log10(df_human[metric] + 1).mean()\n",
        "    else:\n",
        "        ai_mean = df_ai[metric].mean()\n",
        "        human_mean = df_human[metric].mean()\n",
        "    ai_means.append(ai_mean)\n",
        "    human_means.append(human_mean)\n",
        "\n",
        "# 设置柱状图位置\n",
        "x = np.arange(len(mean_metrics))\n",
        "width = 0.35  # 柱子宽度\n",
        "\n",
        "# 绘制柱状图\n",
        "bars1 = plt.bar(x - width/2, ai_means, width, label=labels['AI'], color=colors['AI'], alpha=0.8)\n",
        "bars2 = plt.bar(x + width/2, human_means, width, label=labels['人类'], color=colors['人类'], alpha=0.8)\n",
        "\n",
        "# 添加数值标签\n",
        "def add_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "                 f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "add_labels(bars1)\n",
        "add_labels(bars2)\n",
        "\n",
        "# 设置标签和标题\n",
        "plt.xlabel('指标类型', fontsize=12)\n",
        "plt.ylabel('均值', fontsize=12)\n",
        "plt.title('AI vs 人类视频：关键指标均值对比', fontsize=14, pad=20)\n",
        "plt.xticks(x, [mean_metric_names[m] for m in mean_metrics], fontsize=10, rotation=15)\n",
        "plt.legend(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -------------------------- 5. 其他图表保持不变（此处简化展示，完整代码包含全部6类图表）--------------------------\n",
        "print(\"图表1和图表2已修复并显示，完整代码可生成全a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5WfpVoIQNid"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from snownlp import SnowNLP\n",
        "from matplotlib.patches import Patch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # 忽略无关警告\n",
        "\n",
        "# -------------------------- 1. 基础设置 --------------------------\n",
        "# 中文字体与图表样式\n",
        "plt.rcParams[\"font.family\"] = [\"WenQuanYi Zen Hei\", \"SimHei\"]\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['grid.color'] = '#e0e0e0'\n",
        "\n",
        "# 定义颜色与标签（AI：科技蓝，人类：温暖橙）\n",
        "color_map = {'AI': '#2c7fb8', '人类': '#ff7f00'}\n",
        "label_map = {'AI': 'AI生成视频', '人类': '人类创作视频'}\n",
        "\n",
        "# 情感阈值（0.5为分界，可根据数据微调）\n",
        "POSITIVE_THRESHOLD = 0.5\n",
        "\n",
        "\n",
        "# -------------------------- 2. 数据加载与关联 --------------------------\n",
        "def load_text_data(excel_path, video_type):\n",
        "    \"\"\"\n",
        "    加载Excel中的弹幕/评论数据，关联视频类型\n",
        "    返回：DataFrame（含text文本、video_type视频类型、bvid视频ID）\n",
        "    \"\"\"\n",
        "    # 1. 加载弹幕数据（danmu工作表）\n",
        "    df_danmu = pd.read_excel(excel_path, sheet_name='danmu')[['bvid', 'danmu']]\n",
        "    df_danmu['text_type'] = '弹幕'  # 标记文本类型\n",
        "    df_danmu.rename(columns={'danmu': 'text'}, inplace=True)  # 统一文本列名\n",
        "\n",
        "    # 2. 加载评论数据（comments工作表）\n",
        "    df_comments = pd.read_excel(excel_path, sheet_name='comments')[['bvid', 'message']]\n",
        "    df_comments['text_type'] = '评论'  # 标记文本类型\n",
        "    df_comments.rename(columns={'message': 'text'}, inplace=True)  # 统一文本列名\n",
        "\n",
        "    # 3. 合并数据并添加视频类型\n",
        "    df_combined_text = pd.concat([df_danmu, df_comments], ignore_index=True)\n",
        "    df_combined_text['video_type'] = video_type  # 标记AI/人类视频\n",
        "\n",
        "    # 4. 数据清洗（过滤空文本、短文本）\n",
        "    df_combined_text = df_combined_text.dropna(subset=['text'])  # 删除空文本\n",
        "    df_combined_text['text_length'] = df_combined_text['text'].str.len()\n",
        "    df_combined_text = df_combined_text[df_combined_text['text_length'] >= 2]  # 过滤1字以内无意义文本\n",
        "\n",
        "    return df_combined_text\n",
        "\n",
        "# 加载AI视频和人类视频的文本数据\n",
        "df_ai_text = load_text_data(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\freeloop\\cleaned_data.xlsx', video_type='AI')\n",
        "df_human_text = load_text_data(r'D:\\A CITYUSAMA\\5507final\\cleaned_data(fl).xlsx', video_type='人类')\n",
        "\n",
        "# 合并所有文本数据（用于统一分析）\n",
        "df_all_text = pd.concat([df_ai_text, df_human_text], ignore_index=True)\n",
        "print(f\"数据加载完成：共{len(df_all_text)}条有效文本（AI：{len(df_ai_text)}条，人类：{len(df_human_text)}条）\")\n",
        "print(f\"其中弹幕：{len(df_all_text[df_all_text['text_type'] == '弹幕'])}条，评论：{len(df_all_text[df_all_text['text_type'] == '评论'])}条\")\n",
        "\n",
        "\n",
        "# -------------------------- 3. 情感分析（计算情感评分） --------------------------\n",
        "def calculate_sentiment_score(text):\n",
        "    \"\"\"使用SnowNLP计算文本情感评分（0-1，1为最积极）\"\"\"\n",
        "    try:\n",
        "        return SnowNLP(text).sentiments\n",
        "    except:\n",
        "        return 0.5  # 异常文本返回中性评分\n",
        "\n",
        "# 批量计算情感评分（耗时取决于文本数量，1万条约1分钟）\n",
        "print(\"\\n正在计算情感评分...\")\n",
        "df_all_text['sentiment_score'] = df_all_text['text'].apply(calculate_sentiment_score)\n",
        "\n",
        "# 标记情感类型（积极/消极/中性）\n",
        "df_all_text['sentiment_type'] = np.where(\n",
        "    df_all_text['sentiment_score'] > POSITIVE_THRESHOLD, '积极',\n",
        "    np.where(df_all_text['sentiment_score'] < POSITIVE_THRESHOLD, '消极', '中性')\n",
        ")\n",
        "\n",
        "# 保存情感分析结果到Excel（便于后续查看）\n",
        "df_all_text.to_excel(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\情感分析结果.xlsx', index=False)\n",
        "print(\"情感评分计算完成，结果已保存至：情感分析结果.xlsx\")\n",
        "\n",
        "\n",
        "# -------------------------- 4. 可视化对比1：情感分布占比（饼图+柱状图） --------------------------\n",
        "def plot_sentiment_distribution():\n",
        "    \"\"\"绘制情感类型占比对比图（按视频类型+文本类型分组）\"\"\"\n",
        "    # 1. 计算分组占比（视频类型×文本类型×情感类型）\n",
        "    sentiment_count = df_all_text.groupby(['video_type', 'text_type', 'sentiment_type']).size().unstack(fill_value=0)\n",
        "    sentiment_ratio = sentiment_count.div(sentiment_count.sum(axis=1), axis=0) * 100  # 转换为百分比\n",
        "\n",
        "    # 2. 创建子图（2行1列：弹幕+评论）\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "    text_types = ['弹幕', '评论']\n",
        "    axes = [ax1, ax2]\n",
        "\n",
        "    for idx, text_type in enumerate(text_types):\n",
        "        # 筛选当前文本类型的数据（AI+人类）\n",
        "        ratio_danmu_ai = sentiment_ratio.loc[('AI', text_type)] if ('AI', text_type) in sentiment_ratio.index else pd.Series([0,0,0], index=['消极','中性','积极'])\n",
        "        ratio_danmu_human = sentiment_ratio.loc[('人类', text_type)] if ('人类', text_type) in sentiment_ratio.index else pd.Series([0,0,0], index=['消极','中性','积极'])\n",
        "\n",
        "        # 柱状图位置设置\n",
        "        x = np.arange(3)  # 3种情感类型\n",
        "        width = 0.35\n",
        "\n",
        "        # 绘制柱状图\n",
        "        bars1 = axes[idx].bar(x - width/2, ratio_danmu_ai.values, width,\n",
        "                             label=label_map['AI'], color=color_map['AI'], alpha=0.8)\n",
        "        bars2 = axes[idx].bar(x + width/2, ratio_danmu_human.values, width,\n",
        "                             label=label_map['人类'], color=color_map['人类'], alpha=0.8)\n",
        "\n",
        "        # 添加数值标签（百分比）\n",
        "        for bar in bars1:\n",
        "            height = bar.get_height()\n",
        "            axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                          f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "        for bar in bars2:\n",
        "            height = bar.get_height()\n",
        "            axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "                          f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 子图样式设置\n",
        "        axes[idx].set_title(f'{text_type}情感类型占比对比', fontsize=12, pad=15)\n",
        "        axes[idx].set_xlabel('情感类型', fontsize=10)\n",
        "        axes[idx].set_ylabel('占比（%）', fontsize=10)\n",
        "        axes[idx].set_xticks(x)\n",
        "        axes[idx].set_xticklabels(['消极', '中性', '积极'])\n",
        "        axes[idx].set_ylim(0, 100)  # 百分比范围0-100\n",
        "        axes[idx].legend()\n",
        "\n",
        "    plt.suptitle('AI vs 人类视频：弹幕/评论情感分布对比', fontsize=14, y=0.98)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/情感分布占比对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"\\n图表1：情感分布占比对比图已保存\")\n",
        "\n",
        "# 执行可视化1\n",
        "plot_sentiment_distribution()\n",
        "\n",
        "\n",
        "# -------------------------- 5. 可视化对比2：情感评分均值对比（分组柱状图） --------------------------\n",
        "def plot_sentiment_mean():\n",
        "    \"\"\"绘制情感评分均值对比（按视频类型+文本类型）\"\"\"\n",
        "    # 计算分组均值\n",
        "    sentiment_mean = df_all_text.groupby(['video_type', 'text_type'])['sentiment_score'].agg(['mean', 'count']).round(3)\n",
        "    sentiment_mean.columns = ['情感均值', '文本数量']  # 重命名列\n",
        "\n",
        "    # 创建图表\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # 准备数据\n",
        "    x_labels = []\n",
        "    ai_means = []\n",
        "    human_means = []\n",
        "    ai_counts = []\n",
        "    human_counts = []\n",
        "\n",
        "    for text_type in ['弹幕', '评论']:\n",
        "        # AI视频数据\n",
        "        if ('AI', text_type) in sentiment_mean.index:\n",
        "            ai_means.append(sentiment_mean.loc[('AI', text_type), '情感均值'])\n",
        "            ai_counts.append(sentiment_mean.loc[('AI', text_type), '文本数量'])\n",
        "        else:\n",
        "            ai_means.append(0)\n",
        "            ai_counts.append(0)\n",
        "\n",
        "        # 人类视频数据\n",
        "        if ('人类', text_type) in sentiment_mean.index:\n",
        "            human_means.append(sentiment_mean.loc[('人类', text_type), '情感均值'])\n",
        "            human_counts.append(sentiment_mean.loc[('人类', text_type), '文本数量'])\n",
        "        else:\n",
        "            human_means.append(0)\n",
        "            human_counts.append(0)\n",
        "\n",
        "        x_labels.append(f'{text_type}\\n(AI:{ai_counts[-1]}条/人类:{human_counts[-1]}条)')\n",
        "\n",
        "    # 绘制柱状图\n",
        "    x = np.arange(len(x_labels))\n",
        "    width = 0.35\n",
        "    bars1 = ax.bar(x - width/2, ai_means, width, label=label_map['AI'], color=color_map['AI'], alpha=0.8)\n",
        "    bars2 = ax.bar(x + width/2, human_means, width, label=label_map['人类'], color=color_map['人类'], alpha=0.8)\n",
        "\n",
        "    # 添加均值标签和中性线\n",
        "    for bar in bars1:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "    for bar in bars2:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    ax.axhline(y=POSITIVE_THRESHOLD, color='gray', linestyle='--', alpha=0.7, label='中性阈值(0.5)')\n",
        "\n",
        "    # 图表样式\n",
        "    ax.set_title('AI vs 人类视频：弹幕/评论情感评分均值对比', fontsize=14, pad=20)\n",
        "    ax.set_xlabel('文本类型（括号内为文本数量）', fontsize=12)\n",
        "    ax.set_ylabel('情感评分均值（0-1，越高越积极）', fontsize=12)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(x_labels)\n",
        "    ax.set_ylim(0.3, 0.7)  # 聚焦0.3-0.7区间，更清晰展示差异\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/情感评分均值对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"图表2：情感评分均值对比图已保存\")\n",
        "\n",
        "# 执行可视化2\n",
        "plot_sentiment_mean()\n",
        "\n",
        "\n",
        "# -------------------------- 6. 可视化对比3：情感评分分布密度（小提琴图） --------------------------\n",
        "def plot_sentiment_density():\n",
        "    \"\"\"绘制情感评分分布密度对比（展示离散程度）\"\"\"\n",
        "    # 创建子图（按文本类型分2列）\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    text_types = ['弹幕', '评论']\n",
        "    axes = [ax1, ax2]\n",
        "\n",
        "    for idx, text_type in enumerate(text_types):\n",
        "        # 筛选当前文本类型的情感评分\n",
        "        ai_scores = df_all_text[(df_all_text['video_type'] == 'AI') & (df_all_text['text_type'] == text_type)]['sentiment_score']\n",
        "        human_scores = df_all_text[(df_all_text['video_type'] == '人类') & (df_all_text['text_type'] == text_type)]['sentiment_score']\n",
        "\n",
        "        # 绘制小提琴图（展示分布密度）\n",
        "        parts1 = axes[idx].violinplot(ai_scores, positions=[1], widths=0.8, showmeans=True, showmedians=True)\n",
        "        parts2 = axes[idx].violinplot(human_scores, positions=[2], widths=0.8, showmeans=True, showmedians=True)\n",
        "\n",
        "        # 上色（AI蓝、人类橙）\n",
        "        for pc in parts1['bodies']:\n",
        "            pc.set_facecolor(color_map['AI'])\n",
        "            pc.set_alpha(0.6)\n",
        "        for pc in parts2['bodies']:\n",
        "            pc.set_facecolor(color_map['人类'])\n",
        "            pc.set_alpha(0.6)\n",
        "\n",
        "        # 标记均值（红色点）和中位数（绿色线）\n",
        "        parts1['cmeans'].set_color('red')  # 均值\n",
        "        parts1['cmedians'].set_color('darkgreen')  # 中位数\n",
        "        parts2['cmeans'].set_color('red')\n",
        "        parts2['cmedians'].set_color('darkgreen')\n",
        "\n",
        "        # 子图样式\n",
        "        axes[idx].set_title(f'{text_type}情感评分分布密度', fontsize=12, pad=15)\n",
        "        axes[idx].set_xticks([1, 2])\n",
        "        axes[idx].set_xticklabels([label_map['AI'], label_map['人类']], fontsize=10)\n",
        "        axes[idx].set_ylabel('情感评分（0-1）', fontsize=10)\n",
        "        axes[idx].set_ylim(0, 1)\n",
        "        axes[idx].axhline(y=POSITIVE_THRESHOLD, color='gray', linestyle='--', alpha=0.5, label='中性阈值(0.5)')\n",
        "\n",
        "        # 图例（仅在第一个子图显示）\n",
        "        if idx == 0:\n",
        "            legend_elements = [\n",
        "                Patch(facecolor=color_map['AI'], alpha=0.6, label=label_map['AI']),\n",
        "                Patch(facecolor=color_map['人类'], alpha=0.6, label=label_map['人类']),\n",
        "                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=8, label='均值'),\n",
        "                plt.Line2D([0], [0], color='darkgreen', linewidth=2, label='中位数')\n",
        "            ]\n",
        "            axes[idx].legend(handles=legend_elements, fontsize=9)\n",
        "\n",
        "    plt.suptitle('AI vs 人类视频：弹幕/评论情感评分分布密度对比', fontsize=14, y=0.98)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/mnt/情感评分分布密度对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"图表3：情感评分分布密度对比图已保存\")\n",
        "\n",
        "# 执行可视化3\n",
        "plot_sentiment_density()\n",
        "\n",
        "\n",
        "# -------------------------- 7. 输出情感分析核心结论 --------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"情感分析核心结论\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 计算关键指标\n",
        "for text_type in ['弹幕', '评论']:\n",
        "    ai_data = df_all_text[(df_all_text['video_type'] == 'AI') & (df_all_text['text_type'] == text_type)]\n",
        "    human_data = df_all_text[(df_all_text['video_type'] == '人类') & (df_all_text['text_type'] == text_type)]\n",
        "\n",
        "    if len(ai_data) > 0 and len(human_data) > 0:\n",
        "        ai_mean = ai_data['sentiment_score'].mean().round(3)\n",
        "        human_mean = human_data['sentiment_score'].mean().round(3)\n",
        "        ai_pos_ratio = (ai_data['sentiment_type'] == '积极').sum() / len(ai_data) * 100\n",
        "        human_pos_ratio = (human_data['sentiment_type'] == '积极').sum() / len(human_data) * 100\n",
        "\n",
        "        print(f\"\\n{text_type}维度：\")\n",
        "        print(f\"  AI视频：情感均值{ai_mean}，积极占比{ai_pos_ratio:.1f}%（{len(ai_data)}条文本）\")\n",
        "        print(f\"  人类视频：情感均值{human_mean}，积极占比{human_pos_ratio:.1f}%（{len(human_data)}条文本）\")\n",
        "        print(f\"  差异：{'AI更积极' if ai_mean > human_mean else '人类更积极'}（均值差：{abs(ai_mean - human_mean):.3f}）\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtLsL-t5UAQg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from math import pi\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# -------------------------- 1. 基础设置 --------------------------\n",
        "plt.rcParams[\"font.family\"] = [\"WenQuanYi Zen Hei\", \"SimHei\"]  # 中文字体\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示\n",
        "plt.rcParams['figure.dpi'] = 300  # 高清分辨率\n",
        "plt.rcParams['axes.grid'] = True\n",
        "plt.rcParams['grid.color'] = '#e0e0e0'\n",
        "\n",
        "# 定义颜色与标签\n",
        "color_map = {'AI': '#2c7fb8', '人类': '#ff7f00'}\n",
        "label_map = {'AI': 'AI生成视频', '人类': '人类创作视频'}\n",
        "\n",
        "\n",
        "# -------------------------- 2. 数据加载与预处理 --------------------------\n",
        "def load_data(ai_path, human_path):\n",
        "    \"\"\"加载并合并AI和人类视频的summary数据\"\"\"\n",
        "    # 加载数据\n",
        "    df_ai = pd.read_excel(ai_path, sheet_name='summary')\n",
        "    df_human = pd.read_excel(human_path, sheet_name='summary')\n",
        "\n",
        "    # 添加视频类型标签\n",
        "    df_ai['video_type'] = 'AI'\n",
        "    df_human['video_type'] = '人类'\n",
        "\n",
        "    # 转换发布时间为datetime格式\n",
        "    df_ai['pubdate'] = pd.to_datetime(df_ai['pubdate'])\n",
        "    df_human['pubdate'] = pd.to_datetime(df_human['pubdate'])\n",
        "\n",
        "    # 计算转化率指标\n",
        "    for df in [df_ai, df_human]:\n",
        "        df['like_rate'] = (df['like'] / df['view'] * 100).round(3)  # 点赞率（%）\n",
        "        df['favorite_rate'] = (df['favorite'] / df['view'] * 100).round(3)  # 收藏率（%）\n",
        "\n",
        "    # 合并数据\n",
        "    df_combined = pd.concat([df_ai, df_human], ignore_index=True)\n",
        "    return df_combined, df_ai, df_human\n",
        "\n",
        "# 替换为你的文件路径\n",
        "df_combined, df_ai, df_human = load_data(\n",
        "    ai_path=r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\freeloop\\cleaned_data.xlsx',\n",
        "    human_path=r'D:\\A CITYUSAMA\\5507final\\cleaned_data(fl).xlsx'\n",
        ")\n",
        "\n",
        "# 定义核心指标（用于后续分析）\n",
        "core_metrics = ['view', 'like', 'coin', 'favorite', 'share', 'danmaku', 'reply_count']\n",
        "rate_metrics = ['like_rate', 'favorite_rate']  # 转化率指标\n",
        "\n",
        "\n",
        "# -------------------------- 3. 时间趋势对比（折线图） --------------------------\n",
        "def plot_time_trend():\n",
        "    \"\"\"发布时间 vs 播放量/点赞数 趋势对比（显示并保存图表）\"\"\"\n",
        "    # 按月份聚合数据\n",
        "    df_combined['month'] = df_combined['pubdate'].dt.to_period('M')  # 按月分组\n",
        "    monthly_data = df_combined.groupby(['month', 'video_type']).agg({\n",
        "        'view': 'mean',    # 月均播放量\n",
        "        'like': 'mean'     # 月均点赞数\n",
        "    }).reset_index()\n",
        "    monthly_data['month'] = monthly_data['month'].dt.to_timestamp()  # 转换为时间戳便于绘图\n",
        "\n",
        "    # 创建双Y轴折线图\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # 左侧Y轴：播放量（取log10便于展示）\n",
        "    for vt in ['AI', '人类']:\n",
        "        sub_data = monthly_data[monthly_data['video_type'] == vt]\n",
        "        ax1.plot(sub_data['month'], np.log10(sub_data['view'] + 1),  # +1避免log(0)\n",
        "                 marker='o' if vt == 'AI' else 's',\n",
        "                 linewidth=2, color=color_map[vt],\n",
        "                 label=f'{label_map[vt]} - 播放量')\n",
        "    ax1.set_xlabel('发布月份', fontsize=12)\n",
        "    ax1.set_ylabel('月均播放量（log10）', fontsize=11, color='#333')\n",
        "    ax1.tick_params(axis='y', labelcolor='#333')\n",
        "    ax1.legend(loc='upper left', fontsize=9)\n",
        "\n",
        "    # 右侧Y轴：点赞数\n",
        "    ax2 = ax1.twinx()\n",
        "    for vt in ['AI', '人类']:\n",
        "        sub_data = monthly_data[monthly_data['video_type'] == vt]\n",
        "        ax2.plot(sub_data['month'], sub_data['like'],\n",
        "                 marker='o' if vt == 'AI' else 's',\n",
        "                 linewidth=2, color=color_map[vt], linestyle='--',\n",
        "                 label=f'{label_map[vt]} - 点赞数')\n",
        "    ax2.set_ylabel('月均点赞数', fontsize=11, color='#666')\n",
        "    ax2.tick_params(axis='y', labelcolor='#666')\n",
        "    ax2.legend(loc='upper right', fontsize=9)\n",
        "\n",
        "    # 美化\n",
        "    plt.title('AI vs 人类视频：播放量与点赞数时间趋势', fontsize=14, pad=20)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 保存图片并显示图表（关键修改）\n",
        "    plt.savefig('时间趋势对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()  # 显示图表\n",
        "    print(\"1. 时间趋势对比图已显示并保存\")\n",
        "\n",
        "plot_time_trend()\n",
        "\n",
        "\n",
        "# -------------------------- 4. 互动相关性对比（热力图） --------------------------\n",
        "def plot_correlation_heatmap():\n",
        "    \"\"\"各指标相关系数热力图对比（显示并保存图表）\"\"\"\n",
        "    # 计算两类视频的相关系数矩阵\n",
        "    ai_corr = df_ai[core_metrics].corr().round(2)\n",
        "    human_corr = df_human[core_metrics].corr().round(2)\n",
        "\n",
        "    # 创建2x1子图\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
        "\n",
        "    # AI视频热力图\n",
        "    sns.heatmap(ai_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1,\n",
        "                ax=ax1, cbar=False, square=True)\n",
        "    ax1.set_title(f'{label_map[\"AI\"]} 互动指标相关性', fontsize=12, pad=15)\n",
        "\n",
        "    # 人类视频热力图\n",
        "    sns.heatmap(human_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1,\n",
        "                ax=ax2, cbar=True, square=True)\n",
        "    ax2.set_title(f'{label_map[\"人类\"]} 互动指标相关性', fontsize=12, pad=15)\n",
        "\n",
        "    # 调整颜色条\n",
        "    cbar = ax2.collections[0].colorbar\n",
        "    cbar.set_label('相关系数', fontsize=10)\n",
        "\n",
        "    # 统一坐标轴标签\n",
        "    for ax in [ax1, ax2]:\n",
        "        ax.set_xticklabels(core_metrics, rotation=45, fontsize=9)\n",
        "        ax.set_yticklabels(core_metrics, rotation=0, fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 保存图片并显示图表（关键修改）\n",
        "    plt.savefig('互动相关性热力图对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()  # 显示图表\n",
        "    print(\"2. 互动相关性热力图对比已显示并保存\")\n",
        "\n",
        "plot_correlation_heatmap()\n",
        "\n",
        "\n",
        "# -------------------------- 5. 头部视频对比（雷达图） --------------------------\n",
        "def plot_top_videos_radar(top_n=5):\n",
        "    \"\"\"Top N视频多维度表现对比（显示并保存图表）\"\"\"\n",
        "    # 筛选Top N视频（按播放量排序）\n",
        "    ai_top = df_ai.nlargest(top_n, 'view')[core_metrics].reset_index(drop=True)\n",
        "    human_top = df_human.nlargest(top_n, 'view')[core_metrics].reset_index(drop=True)\n",
        "\n",
        "    # 全局标准化（确保两类视频在同一尺度）\n",
        "    all_top_data = pd.concat([ai_top, human_top], ignore_index=True)\n",
        "    global_min = all_top_data.min()\n",
        "    global_max = all_top_data.max()\n",
        "\n",
        "    def normalize(data):\n",
        "        return (data - global_min) / (global_max - global_min + 1e-6)  # 避免除零\n",
        "\n",
        "    ai_top_norm = ai_top.apply(normalize, axis=1)\n",
        "    human_top_norm = human_top.apply(normalize, axis=1)\n",
        "\n",
        "    # 雷达图参数\n",
        "    N = len(core_metrics)\n",
        "    angles = [n / N * 2 * pi for n in range(N)]\n",
        "    angles += angles[:1]  # 闭合图形\n",
        "\n",
        "    # 创建图表\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # 绘制AI头部视频\n",
        "    for i in range(min(top_n, len(ai_top_norm))):\n",
        "        values = ai_top_norm.iloc[i].tolist() + [ai_top_norm.iloc[i, 0]]  # 闭合\n",
        "        ax.plot(angles, values, 'o-', linewidth=2,\n",
        "                color=color_map['AI'], alpha=0.7,\n",
        "                label=f'{label_map[\"AI\"]} Top{i+1}')\n",
        "        ax.fill(angles, values, alpha=0.1, color=color_map['AI'])\n",
        "\n",
        "    # 绘制人类头部视频\n",
        "    for i in range(min(top_n, len(human_top_norm))):\n",
        "        values = human_top_norm.iloc[i].tolist() + [human_top_norm.iloc[i, 0]]  # 闭合\n",
        "        ax.plot(angles, values, 's-', linewidth=2,\n",
        "                color=color_map['人类'], alpha=0.7,\n",
        "                label=f'{label_map[\"人类\"]} Top{i+1}')\n",
        "        ax.fill(angles, values, alpha=0.1, color=color_map['人类'])\n",
        "\n",
        "    # 美化\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(core_metrics, fontsize=9)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
        "    ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=8)\n",
        "    ax.set_title(f'Top{top_n}头部视频多维度对比', fontsize=14, pad=20)\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 保存图片并显示图表（关键修改）\n",
        "    plt.savefig(f'Top{top_n}头部视频雷达图.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()  # 显示图表\n",
        "    print(f\"3. Top{top_n}头部视频雷达图已显示并保存\")\n",
        "\n",
        "plot_top_videos_radar(top_n=5)  # 可修改为3/5/10等\n",
        "\n",
        "\n",
        "# -------------------------- 6. 互动转化率对比（小提琴图） --------------------------\n",
        "def plot_conversion_rate():\n",
        "    \"\"\"点赞率/收藏率分布密度对比（显示并保存图表）\"\"\"\n",
        "    # 创建2x1子图（按转化率类型）\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    rate_labels = ['点赞率（%）', '收藏率（%）']\n",
        "    axes = [ax1, ax2]\n",
        "\n",
        "    for idx, metric in enumerate(rate_metrics):\n",
        "        # 提取两类视频的转化率数据\n",
        "        ai_data = df_ai[metric].dropna()\n",
        "        human_data = df_human[metric].dropna()\n",
        "\n",
        "        # 绘制小提琴图\n",
        "        parts1 = axes[idx].violinplot(ai_data, positions=[1], widths=0.8,\n",
        "                                     showmeans=True, showmedians=True)\n",
        "        parts2 = axes[idx].violinplot(human_data, positions=[2], widths=0.8,\n",
        "                                     showmeans=True, showmedians=True)\n",
        "\n",
        "        # 上色\n",
        "        for pc in parts1['bodies']:\n",
        "            pc.set_facecolor(color_map['AI'])\n",
        "            pc.set_alpha(0.6)\n",
        "        for pc in parts2['bodies']:\n",
        "            pc.set_facecolor(color_map['人类'])\n",
        "            pc.set_alpha(0.6)\n",
        "\n",
        "        # 标记均值（红点）和中位数（绿线）\n",
        "        parts1['cmeans'].set_color('red')\n",
        "        parts1['cmedians'].set_color('darkgreen')\n",
        "        parts2['cmeans'].set_color('red')\n",
        "        parts2['cmedians'].set_color('darkgreen')\n",
        "\n",
        "        # 美化\n",
        "        axes[idx].set_title(rate_labels[idx], fontsize=12, pad=15)\n",
        "        axes[idx].set_xticks([1, 2])\n",
        "        axes[idx].set_xticklabels([label_map['AI'], label_map['人类']], fontsize=10)\n",
        "        axes[idx].set_ylabel('转化率（%）', fontsize=10)\n",
        "        axes[idx].set_ylim(0, max(ai_data.max(), human_data.max()) * 1.1)  # 留10%余量\n",
        "\n",
        "        # 添加图例（仅第一个子图）\n",
        "        if idx == 0:\n",
        "            legend_elements = [\n",
        "                Patch(facecolor=color_map['AI'], alpha=0.6, label=label_map['AI']),\n",
        "                Patch(facecolor=color_map['人类'], alpha=0.6, label=label_map['人类']),\n",
        "                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red',\n",
        "                          markersize=8, label='均值'),\n",
        "                plt.Line2D([0], [0], color='darkgreen', linewidth=2, label='中位数')\n",
        "            ]\n",
        "            axes[idx].legend(handles=legend_elements, fontsize=9)\n",
        "\n",
        "    plt.suptitle('AI vs 人类视频：互动转化率分布对比', fontsize=14, y=0.98)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 保存图片并显示图表（关键修改）\n",
        "    plt.savefig('互动转化率对比.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()  # 显示图表\n",
        "    print(\"4. 互动转化率对比图已显示并保存\")\n",
        "\n",
        "plot_conversion_rate()\n",
        "\n",
        "print(\"\\n所有图表已显示并保存为PNG文件！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 核心：指定字体列表（按优先级排序，系统会自动选第一个存在的）\n",
        "# Windows 常见中文字体：SimHei(黑体)、Microsoft YaHei(微软雅黑)、SimSun(宋体)\n",
        "# Mac 常见中文字体：Heiti TC(黑体-繁)、Songti SC(宋体-简)、Arial Unicode MS\n",
        "# Linux 常见中文字体：WenQuanYi Zen Hei(文泉驿)、Noto Sans CJK SC(思源黑体)\n",
        "plt.rcParams['font.sans-serif'] = [\n",
        "    'SimHei',          # Windows 优先\n",
        "    'Microsoft YaHei',\n",
        "    'Heiti TC',        # Mac 优先\n",
        "    'Songti SC',\n",
        "    'WenQuanYi Zen Hei',# Linux 优先\n",
        "    'Noto Sans CJK SC',\n",
        "    'DejaVu Sans'      # 最终 fallback（英文无乱码）\n",
        "]\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示为方块的问题\n",
        "\n",
        "# 验证字体是否生效（可选）\n",
        "def check_font():\n",
        "    font_names = [f.name for f in fm.fontManager.ttflist]\n",
        "    for font in plt.rcParams['font.sans-serif']:\n",
        "        if font in font_names:\n",
        "            print(f\"当前使用字体：{font}\")\n",
        "            return\n",
        "    print(\"警告：未找到指定中文字体，将使用默认英文字体（中文可能显示异常）\")\n",
        "\n",
        "check_font()  # 运行后可查看实际使用的字体\n",
        "\n",
        "# 重新加载原始数据（模拟清洗前状态）\n",
        "# 评论数据\n",
        "raw_comments = pd.read_csv(r'D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-悬溺\\bili_covers_comments_悬溺_Ai翻唱_20251106_203434.csv')\n",
        "# 弹幕数据\n",
        "raw_danmu = pd.read_csv(r'D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-悬溺\\bili_covers_danmu_悬溺_Ai翻唱_20251106_203434.csv')\n",
        "# 视频汇总数据\n",
        "raw_summary = pd.read_csv(r'D:\\A CITYUSAMA\\5507final\\metadata\\bilibili_Ai_翻唱（5000limit）\\Ai-悬溺\\bili_covers_summary_悬溺_Ai翻唱_20251106_203434.csv')\n",
        "\n",
        "# 加载清洗后的数据\n",
        "cleaned_comments = pd.read_excel(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺\\cleaned_data xn.xlsx', sheet_name='comments')\n",
        "cleaned_danmu = pd.read_excel(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺\\cleaned_data xn.xlsx', sheet_name='danmu')\n",
        "cleaned_summary = pd.read_excel(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺\\cleaned_data xn.xlsx', sheet_name='summary')\n",
        "\n",
        "# 计算清洗前后核心指标\n",
        "metrics = {\n",
        "    '数据类型': ['评论数据', '评论数据', '评论数据', '弹幕数据', '弹幕数据', '弹幕数据', '视频汇总数据', '视频汇总数据', '视频汇总数据'],\n",
        "    '指标名称': ['总记录数', '重复记录数', '缺失值记录数', '总记录数', '重复记录数', '无效弹幕数', '总视频数', '重复视频数', '信息完整视频数'],\n",
        "    '清洗前': [\n",
        "        len(raw_comments),\n",
        "        len(raw_comments) - len(raw_comments.drop_duplicates()),\n",
        "        raw_comments.isnull().any(axis=1).sum(),\n",
        "        len(raw_danmu),\n",
        "        len(raw_danmu) - len(raw_danmu.drop_duplicates()),\n",
        "        sum(raw_danmu['danmu'].str.strip().isin(['', ' ', '666', '哈哈哈']).fillna(True)),\n",
        "        len(raw_summary),\n",
        "        len(raw_summary) - len(raw_summary.drop_duplicates()),\n",
        "        sum(raw_summary[['view', 'like', 'coin', 'favorite']].notnull().all(axis=1)),\n",
        "    ],\n",
        "    '清洗后': [\n",
        "        len(cleaned_comments),\n",
        "        0,  # 已去重\n",
        "        cleaned_comments.isnull().any(axis=1).sum(),\n",
        "        len(cleaned_danmu),\n",
        "        0,  # 已去重\n",
        "        0,  # 已过滤无效弹幕\n",
        "        len(cleaned_summary),\n",
        "        0,  # 已去重\n",
        "        sum(cleaned_summary[['view', 'like', 'coin', 'favorite']].notnull().all(axis=1)),\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 创建对比表格\n",
        "comparison_df = pd.DataFrame(metrics)\n",
        "\n",
        "# 保存对比表格为Excel\n",
        "with pd.ExcelWriter(r'D:\\A CITYUSAMA\\5507final\\ai数据清洗\\悬溺\\数据清洗前后对比表.xlsx', engine='openpyxl') as writer:\n",
        "    comparison_df.to_excel(writer, sheet_name='清洗前后对比', index=False)\n",
        "\n",
        "# 1. 制作清洗前后总记录数对比柱状图\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# 柱状图：核心数据类型的总记录数对比\n",
        "data_types = ['评论数据', '弹幕数据', '视频汇总数据']\n",
        "before_counts = [\n",
        "    len(raw_comments),\n",
        "    len(raw_danmu),\n",
        "    len(raw_summary)\n",
        "]\n",
        "after_counts = [\n",
        "    len(cleaned_comments),\n",
        "    len(cleaned_danmu),\n",
        "    len(cleaned_summary)\n",
        "]\n",
        "\n",
        "x = np.arange(len(data_types))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax1.bar(x - width/2, before_counts, width, label='清洗前', color='#ff7f7f', alpha=0.8)\n",
        "bars2 = ax1.bar(x + width/2, after_counts, width, label='清洗后', color='#7fbf7f', alpha=0.8)\n",
        "\n",
        "ax1.set_xlabel('数据类型')\n",
        "ax1.set_ylabel('记录数')\n",
        "ax1.set_title('数据清洗前后总记录数对比')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(data_types)\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 在柱状图上添加数值标签\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# 2. 制作清洗后有效数据占比饼图（以评论数据为例，突出清洗效果）\n",
        "comment_clean_effect = [\n",
        "    len(cleaned_comments),  # 有效数据\n",
        "    len(raw_comments) - len(cleaned_comments)  # 清洗掉的数据（重复+缺失+无效）\n",
        "]\n",
        "labels = ['有效评论', '清洗掉的无效数据']\n",
        "colors = ['#66b3ff', '#ffcc99']\n",
        "explode = (0.05, 0)  # 突出有效数据\n",
        "\n",
        "ax2.pie(comment_clean_effect, labels=labels, colors=colors, explode=explode, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "ax2.set_title('评论数据清洗后有效占比')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/mnt/数据清洗前后对比图表.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 3. 制作缺失值修复对比柱状图\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "missing_metrics = ['评论缺失值', '弹幕缺失值', '视频信息缺失值']\n",
        "before_missing = [\n",
        "    raw_comments.isnull().any(axis=1).sum(),\n",
        "    raw_danmu.isnull().any(axis=1).sum(),\n",
        "    len(raw_summary) - sum(raw_summary[['view', 'like', 'coin', 'favorite']].notnull().all(axis=1))\n",
        "]\n",
        "after_missing = [\n",
        "    cleaned_comments.isnull().any(axis=1).sum(),\n",
        "    cleaned_danmu.isnull().any(axis=1).sum(),\n",
        "    len(cleaned_summary) - sum(cleaned_summary[['view', 'like', 'coin', 'favorite']].notnull().all(axis=1))\n",
        "]\n",
        "\n",
        "x = np.arange(len(missing_metrics))\n",
        "bars1 = ax.bar(x - width/2, before_missing, width, label='清洗前', color='#ff9999', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, after_missing, width, label='清洗后', color='#99ff99', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('数据类型')\n",
        "ax.set_ylabel('缺失值记录数')\n",
        "ax.set_title('数据清洗前后缺失值修复对比')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(missing_metrics)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 添加数值标签\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "             f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "欢迎使用 Colab",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
